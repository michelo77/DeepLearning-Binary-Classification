# -*- coding: utf-8 -*-
"""machineLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_6kEItVWGNu96MSk1c-vqmm8THut3fCO
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# Leer archivos desde una carpeta (debe subir como archivo)
from google.colab import drive

import zipfile
zip_ref = zipfile.ZipFile('/content/dataset1.zip', 'r')
zip_ref.extractall('/content')

# Redimensionar las imágenes. Normalizar las imágenes para que los valores de los píxeles estén entre 0 y 1, convertir en rgb, agregar a lista de Python para dos clases Cats y Dogs, conciderando que estas se encuentran ubicadas en diferentes rutas

def preprocess_images(image_paths, image_size=(224, 224)):

  processed_images = []
  for image_path in image_paths:
    try:
      image = cv2.imread(image_path)
      if image is None:
        print(f"Error al cargar la imagen: {image_path}")
        continue

      image = cv2.resize(image, image_size)
      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convertir a RGB
      image = image / 255.0  # Normalizar
      processed_images.append(image)
    except Exception as e:
      print(f"Error al procesar la imagen {image_path}: {e}")

  return processed_images


# Listas para almacenar imágenes de gatos y perros
cats_images = []
dogs_images = []

# Ruta a la carpeta donde se encuentran las imágenes
cats_folder = '/content/dataset1/Cats'
dogs_folder = '/content/dataset1/Dogs'


# Obtener las rutas de todas las imágenes en las carpetas de gatos y perros
cats_image_paths = [os.path.join(cats_folder, filename) for filename in os.listdir(cats_folder) if filename.endswith(('.jpg', '.png', '.jpeg'))]
dogs_image_paths = [os.path.join(dogs_folder, filename) for filename in os.listdir(dogs_folder) if filename.endswith(('.jpg', '.png', '.jpeg'))]


# Procesar las imágenes de gatos y guardarlas en la lista
cats_images = preprocess_images(cats_image_paths)

# Procesar las imágenes de perros y guardarlas en la lista
dogs_images = preprocess_images(dogs_image_paths)

print(f"Número de imágenes de gatos: {len(cats_images)}")
print(f"Número de imágenes de perros: {len(dogs_images)}")

# Definir el generador de imágenes con aumento
data = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)

# Divide el conjunto de datos en entrenamiento y validación (80% entrenamiento y 20% validación es común).

data = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)

# Unir imágenes de perros y gatos
imagenes = np.concatenate([dogs_images, cats_images])

# Etiquetas: 1 para perros, 0 para gatos
tag_dogs = np.ones(len(dogs_images))   # Perros con etiqueta 1
tag_cats = np.zeros(len(cats_images))  # Gatos con etiqueta 0
# Unir etiquetas
etiquetas = np.concatenate([tag_dogs, tag_cats])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Crear un generador de datos con ImageDataGenerator
data_gen = ImageDataGenerator(validation_split=0.2)  # Reservar 20% para validación

# Generador para el conjunto de entrenamiento
train_generator = data_gen.flow_from_directory(
    'dataset1/',            # Directorio base
    target_size=(128, 128), # Tamaño de las imágenes
    batch_size=32,          # Tamaño del lote
    class_mode='binary',    # Modo de clasificación binaria
    subset='training'       # Subconjunto de entrenamiento
)

# Generador para el conjunto de validación
validation_generator = data_gen.flow_from_directory(
    'dataset1/',            # Directorio base
    target_size=(128, 128), # Tamaño de las imágenes
    batch_size=32,          # Tamaño del lote
    class_mode='binary',    # Modo de clasificación binaria
    subset='validation'     # Subconjunto de validación
)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # 1 salida para clasificación binaria
])
#Compilar modelo
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    epochs=1,  # Ajusta el número de épocas según sea necesario
    validation_data=validation_generator
)

validation_loss, validation_acc = model.evaluate(validation_generator)
print(f'Exactitud en validación: {validation_acc:.2f}')

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Función para cargar y preprocesar la imagen
def cargar_y_preprocesar_imagen(ruta_imagen):
    img = image.load_img(ruta_imagen, target_size=(128, 128))  # Cargar la imagen y redimensionar a (128, 128)
    img_array = image.img_to_array(img)  # Convertir a un array numpy
    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión extra para el lote
    img_array /= 255.0  # Normalizar la imagen (si tu modelo fue entrenado con imágenes normalizadas)
    return img_array

# Ruta de la imagen (suponiendo que está en /content)
ruta_imagen = '/content/dataset1/Dogs/66.jpg'  # Cambia esto por el nombre de la imagen que quieras probar
imagen_procesada = cargar_y_preprocesar_imagen(ruta_imagen)

# Realizar la predicción
prediccion = model.predict(imagen_procesada)

# Mostrar la imagen
plt.imshow(image.load_img(ruta_imagen))
plt.axis('off')  # Ocultar los ejes
plt.show()

# Interpretar el resultado
if prediccion > 0.49:
    print("Es un perro con una probabilidad de:", prediccion)
else:
    print("Es un gato con una probabilidad de:", 1- prediccion)
